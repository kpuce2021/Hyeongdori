## **ğŸˆ *ë”¥ ëŸ¬ë‹ Yolo v5 ëª¨ë¸*** <br> 

***

<br> 

### **ğŸ“Œ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì§€ì •**

```python
# Directories
    wdir = save_dir / 'weights'
    wdir.mkdir(parents=True, exist_ok=True)  # make dir
    last = wdir / 'last.pt'
    best = wdir / 'best.pt'
    results_file = save_dir / 'results.txt'
```

<br> 

***



### **ğŸ“Œ ê·¸ë˜í”„ ìƒì„± ë° ë°ì´í„° íŠ¹ì§• ì„¤ì •**

- ê·¸ë˜í”„ ìƒì„±
- ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ì¥ì¹˜ì˜ íƒ€ì… ì„¤ì •
- ë°ì´í„° íŠ¹ì§• ì„¤ì •
- í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì • 


```python
 # Configure
    plots = not opt.evolve  # create plots
    cuda = device.type != 'cpu' # ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•  ì¥ì¹˜ íƒ€ì… ì„¤ì • 
    init_seeds(2 + rank)
    with open(opt.data) as f:
        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict
    with torch_distributed_zero_first(rank):
        check_dataset(data_dict)  # check
    train_path = data_dict['train'] # í•™ìŠµ ë°ì´í„° íŠ¹ì§• ì„¤ì •
    test_path = data_dict['val'] # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŠ¹ì§• ì„¤ì • 
    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes
    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names
    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
```

<br> 

***



### **ğŸ“Œ ë°ì´í„°ë¥¼ ì¥ì¹˜ë¡œ load í•˜ëŠ” ë¶€ë¶„**

- torch.load() : pickleì„ ì‚¬ìš©í•´ì„œ ì €ì¥ëœ ê°ì²´ íŒŒì¼ë“¤ì„ ì—­ì§ë ¬í™”, ë©”ëª¨ë¦¬ì— load
- GPUì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ CPUì—ì„œ ë¶ˆëŸ¬ì˜¬ ë•Œ torch.load() í•¨ìˆ˜ì˜ map_location ì¸ìì— deviceë¥¼ ì „ë‹¬í•œë‹¤.
- deviceëŠ” ìœ„ì— ê·¸ë˜í”„ ìƒì„± ë° ë°ì´í„° íŠ¹ì§• ì„¤ì • ë¶€ë¶„ì—ì„œ 'cpu'ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤.


```python
# Model
    pretrained = weights.endswith('.pt')
    if pretrained:
        with torch_distributed_zero_first(rank):
            attempt_download(weights)  # download if not found locally
            
            # torch.load() : pickleì„ ì‚¬ìš©í•´ì„œ ì €ì¥ëœ ê°ì²´ íŒŒì¼ë“¤ì„ ì—­ì§ë ¬í™”, ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼
            # ë°ì´í„°ë¥¼ ì¥ì¹˜ì— ë¶ˆëŸ¬ì˜¬ ë•Œë„ ì‚¬ìš©í•œë‹¤.
            # GPUì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ CPUì—ì„œ ë¶ˆëŸ¬ì˜¬ ë•Œ torch.load() í•¨ìˆ˜ì˜ map_locationì¸ìì— deviceë¥¼ ì „ë‹¬
            # deviceëŠ” ln[3] ì½”ë“œ ë¶€ë¶„ì— 2ë²ˆì§¸ ì¤„ì— cpuë¡œ ì„¤ì •ë˜ì–´ ìˆìŒ 
        ckpt = torch.load(weights, map_location=device)  # load checkpoint
        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create
        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys
        state_dict = ckpt['model'].float().state_dict()  # to FP32
        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect
        
        # load_state_dict() : ì—­ì§ë ¬í™”ëœ state_dictì„ ì‚¬ìš©í•´ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë“¤ì„ ë¶ˆëŸ¬ì˜¨ë‹¤
        model.load_state_dict(state_dict, strict=False)  # load
        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report
    else:
        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create
# ëª¨ë¸ë§Œë“¤ê¸°
```


```python
 # 
    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,
                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,
                                            world_size=opt.world_size, workers=opt.workers,
                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))
    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class
    nb = len(dataloader)  # number of batches
    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)

    # Process 0
    if rank in [-1, 0]:
        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader
                                       hyp=hyp, cache=opt.cache_images and not opt.notest, rect=True, rank=-1,
                                       world_size=opt.world_size, workers=opt.workers,
                                       pad=0.5, prefix=colorstr('val: '))[0]

        if not opt.resume:
            labels = np.concatenate(dataset.labels, 0)
            c = torch.tensor(labels[:, 0])  # classes
            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency
            # model._initialize_biases(cf.to(device))
            if plots:
                plot_labels(labels, save_dir, loggers)
                if tb_writer:
                    tb_writer.add_histogram('classes', c, 0)

            # Anchors
            if not opt.noautoanchor:
                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)
            model.half().float()  # pre-reduce anchor precision
```

<br> 

***



### **ğŸ“Œ ì†ì‹¤ ê³„ì‚°**

- í•™ìŠµ í›„ ìœ„ì¹˜ì™€ ì‚¬ìš©ìê°€ ì›í–ˆë˜ ìœ„ì¹˜ì˜ ì°¨ë¥¼ ì´ìš©í•˜ì—¬ ê³„ì‚°
- ê° ê±°ë¦¬ì˜ ì°¨ì´ë¥¼ ì œê³± í›„ í•©ì‚°í•œ í›„ì— í‰ê·  ì‚°ì¶œ
- compute_loss() : í‰ê·  ì œê³± ì˜¤ì°¨ë²• ì‚¬ìš©

![asd](https://user-images.githubusercontent.com/55940552/110907323-90821a80-8350-11eb-8cc1-e7fccaeda02b.PNG) 


```python
# Forward
            with amp.autocast(enabled=cuda):
                pred = model(imgs)  # forward
            # compute_loss : ì†ì‹¤ ê³„ì‚° í•¨ìˆ˜ 
            # í‰ê·  ì œê³± ì˜¤ì°¨ 
                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size
                if rank != -1:
                    loss *= opt.world_size  # gradient averaged between devices in DDP mode
                if opt.quad:
                    loss *= 4.

            # Backward
            scaler.scale(loss).backward()
            
# ê° ê±°ë¦¬ ì°¨ì´ë¥¼ ì œê³±í•˜ì—¬ í•©ì‚°í•œ í›„ì— í‰ê· ì„ ë‚¸ë‹¤.
# (i+1) : ì „ì²´ ë°ì´í„°ì˜ ìˆ˜
# E = 1/ì „ì²´ ë°ì´í„°ì˜ ìˆ˜ * (for(k=0; k<ì „ì²´ ë°ì´í„°ì˜ ìˆ˜; k++) {(kë²ˆì§¸ y - kë²ˆì§¸ t)^2})
mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses
```


```python
# ì†ì‹¤ ê³„ì‚° í•¨ìˆ˜ ë‚´ë¶€ 
# í‰ê·  ì œê³± ì˜¤ì°¨ : ëª¨ë¸ì˜ ì¶œë ¥ê°’ê³¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¶œë ¥ ê°’ ì‚¬ì´ì˜ ê±°ë¦¬ ì°¨ì´ë¥¼ ì˜¤ì°¨ë¡œ ì‚¬ìš©

def compute_loss(self, weights):
        num_classes = weights.size(0)
        cos = torch.mm(weights, weights.t())
        if not self.normalize_weights:
            norms = self.weight_norms.unsqueeze(1)
            cos = cos / (norms*norms.t())

        cos1 = cos.clone()
        with torch.no_grad():
            row_nums = torch.arange(num_classes).long().to(weights.device)
            cos1[row_nums, row_nums] = -float('inf')
            _, indices = torch.max(cos1, dim=1)
            mask = torch.zeros((num_classes, num_classes)).to(weights.device)
            mask[row_nums, indices] = 1
        
        return {"loss": {"losses": torch.sum(cos*mask, dim=1), "indices": c_f.torch_arange_from_size(weights), "reduction_type": "element"}} 
```



<br> 

***

<br>

**[ì¶œì²˜]**

[í‹°ìŠ¤í† ë¦¬](https://kolikim.tistory.com/36)

[í•œêµ­ì‚°ì—…ê¸°ìˆ ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ë¶€](http://www.kpu.ac.kr/index.do?sso=ok)